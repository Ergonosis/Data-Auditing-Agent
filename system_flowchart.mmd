flowchart TB
    subgraph DataLayer["ğŸ—„ï¸ DATA LAYER - Databricks"]
        KG["Knowledge Graph<br/><i>Entity linking across sources</i><br/><sub>Neo4j, Neptune, or Delta Lake</sub>"]

        subgraph Medallion["Medallion Architecture"]
            Bronze["Bronze Tables<br/><i>Raw ingested data</i>"]
            Silver["Silver Tables<br/><i>Cleaned & validated</i>"]
            Gold["Gold Tables<br/><i>Business aggregates</i>"]
        end

        Bronze --> Silver --> Gold
    end

    subgraph TriggerLayer["â° TRIGGER LAYER"]
        TimeTrigger["Time-Based Trigger<br/><i>Hourly cron job</i><br/><sub>Databricks Workflows scheduler</sub>"]
        EventTrigger["Event-Based Trigger<br/><i>New data arrival</i><br/><sub>Delta Lake change data feed</sub>"]
        ManualTrigger["Manual Trigger<br/><i>On-demand audit</i><br/><sub>API endpoint or UI button</sub>"]
    end

    subgraph OrchestratorLayer["ğŸ¯ ORCHESTRATOR LAYER"]
        Orchestrator["Orchestrator Agent<br/><b>CrewAI Manager</b><br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/><i>Coordinates all sub-agents</i><br/><i>Manages workflow state</i><br/><i>Handles failures & retries</i>"]

        StateStore["Workflow State Store<br/><sub>Redis or Databricks table</sub><br/>â€¢ Current audit run ID<br/>â€¢ Agent status tracking<br/>â€¢ Intermediate results<br/>â€¢ Graceful degradation state"]
    end

    subgraph AgentLayer["ğŸ¤– AGENT LAYER - Parallel Execution"]

        subgraph Agent1["ğŸ“Š Data Quality Agent"]
            DQGoal["<b>Goal:</b> Validate data completeness & integrity"]
            DQTools["<b>Tools:</b><br/>â€¢ check_data_completeness()<br/>â€¢ validate_schema_conformity()<br/>â€¢ detect_duplicate_records()<br/>â€¢ infer_domain_freshness()<br/>â€¢ check_data_quality_gates()"]
            DQOutput["<b>Output:</b><br/>Quality score (0-100)<br/>List of incomplete/invalid records<br/>Domain freshness violations"]
        end

        subgraph Agent2["ğŸ”— Reconciliation Agent"]
            RecGoal["<b>Goal:</b> Match transactions across sources"]
            RecTools["<b>Tools:</b><br/>â€¢ cross_source_matcher()<br/>â€¢ entity_resolver_kg()<br/>â€¢ fuzzy_vendor_matcher()<br/>â€¢ receipt_transaction_matcher()<br/>â€¢ find_orphan_transactions()"]
            RecOutput["<b>Output:</b><br/>Matched transaction pairs<br/>Unmatched transactions (suspicious)<br/>Confidence scores per match"]
        end

        subgraph Agent3["ğŸš¨ Anomaly Detection Agent"]
            AnomalyGoal["<b>Goal:</b> Detect statistical & ML-based anomalies"]
            AnomalyTools["<b>Tools:</b><br/>â€¢ run_isolation_forest()<br/>â€¢ check_vendor_spending_profile()<br/>â€¢ detect_amount_outliers()<br/>â€¢ time_series_deviation_check()<br/>â€¢ batch_anomaly_scorer()"]
            AnomalyOutput["<b>Output:</b><br/>Anomaly scores (0-1)<br/>Flagged transactions with reasons<br/>Vendor profile deviations"]
        end

        subgraph Agent4["ğŸ” Context Enrichment Agent"]
            ContextGoal["<b>Goal:</b> Find supporting documentation"]
            ContextTools["<b>Tools:</b><br/>â€¢ search_emails_batch()<br/>â€¢ search_calendar_events()<br/>â€¢ extract_approval_chains()<br/>â€¢ find_receipt_images()<br/>â€¢ semantic_search_documents()"]
            ContextOutput["<b>Output:</b><br/>Linked emails/calendar events<br/>Approval status per transaction<br/>Missing documentation list"]
        end

        subgraph Agent5["âš–ï¸ Escalation Agent"]
            EscGoal["<b>Goal:</b> Classify severity & generate explanations"]
            EscTools["<b>Tools:</b><br/>â€¢ calculate_severity_score()<br/>â€¢ generate_root_cause_analysis()<br/>â€¢ batch_classify_with_llm()<br/>â€¢ create_audit_flag()<br/>â€¢ check_escalation_rules()"]
            EscOutput["<b>Output:</b><br/>ğŸ”´ CRITICAL flags<br/>ğŸŸ¡ WARNING flags<br/>ğŸ”µ INFO flags<br/>Natural language explanations"]
        end

        subgraph Agent6["ğŸ“ Audit Logging Agent"]
            LogGoal["<b>Goal:</b> Record everything for transparency"]
            LogTools["<b>Tools:</b><br/>â€¢ log_agent_decision()<br/>â€¢ create_audit_trail_entry()<br/>â€¢ save_workflow_state()<br/>â€¢ generate_lineage_trace()<br/>â€¢ archive_to_immutable_log()"]
            LogOutput["<b>Output:</b><br/>Audit trail database entries<br/>Lineage graph (what led to what)<br/>Compliance-ready logs"]
        end
    end

    subgraph DecisionLayer["ğŸ’¡ DECISION & FLAGGING ENGINE"]
        Aggregator["Flag Aggregator<br/><i>Combines all agent outputs</i>"]

        Classifier["Severity Classifier<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ”´ <b>CRITICAL</b>:<br/>  â€¢ Unauthorized >$X<br/>  â€¢ Missing revenue<br/>  â€¢ Compliance violations<br/>ğŸŸ¡ <b>WARNING</b>:<br/>  â€¢ Unusual patterns<br/>  â€¢ Missing receipts<br/>  â€¢ Amount mismatches<br/>ğŸ”µ <b>INFO</b>:<br/>  â€¢ Minor discrepancies<br/>  â€¢ Audit trail only"]

        Explainer["Explainability Engine<br/><i>Generates human-readable reasons</i><br/><sub>Uses SHAP for ML, citations for LLM</sub>"]
    end

    subgraph OutputLayer["ğŸ“¤ OUTPUT & STORAGE"]
        FlagDB[("ğŸš© Flag Database<br/><i>Pending review items</i><br/><sub>Postgres or Databricks table</sub><br/>â€¢ flag_id (UUID)<br/>â€¢ transaction_id<br/>â€¢ severity level<br/>â€¢ confidence score<br/>â€¢ explanation<br/>â€¢ supporting_evidence_links<br/>â€¢ created_at<br/>â€¢ reviewed (boolean)")]

        AuditDB[("ğŸ“œ Audit Trail DB<br/><i>Immutable compliance logs</i><br/><sub>Append-only Delta table</sub><br/>â€¢ audit_run_id<br/>â€¢ agent_name<br/>â€¢ tool_called<br/>â€¢ input_data<br/>â€¢ output_data<br/>â€¢ timestamp<br/>â€¢ llm_tokens_used<br/>â€¢ cost_incurred")]

        Frontend["Frontend Dashboard<br/><i>Finance team interface</i><br/>â€¢ View flagged items<br/>â€¢ Mark as valid/invalid<br/>â€¢ Escalate/de-escalate<br/>â€¢ Add notes<br/>â€¢ Approve bulk items"]
    end

    subgraph FeedbackLayer["ğŸ” FEEDBACK & LEARNING LOOP"]
        HumanFeedback["Human Feedback Collection<br/><i>From frontend interactions</i>"]

        FeedbackAnalyzer["Feedback Analyzer<br/><i>Weekly batch job</i><br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Analyzes patterns:<br/>â€¢ Vendor X: 80% false positives â†’ whitelist<br/>â€¢ Rule Y: 50+ false flags â†’ adjust threshold<br/>â€¢ Agent Z: Low confidence â†’ retrain"]

        RuleTuner["Automatic Rule Tuner<br/><i>No human approval needed</i><br/>Updates:<br/>â€¢ Vendor whitelists/blacklists<br/>â€¢ Dollar thresholds<br/>â€¢ Anomaly detection params<br/>â€¢ Domain freshness configs"]

        ModelRetrainer["ML Model Retrainer<br/><i>Monthly retraining</i><br/>Uses labeled data from review queue"]
    end

    subgraph MonitoringLayer["ğŸ“Š MONITORING & OBSERVABILITY"]
        Metrics["System Metrics<br/>â€¢ Audit completion time<br/>â€¢ Agent success/failure rates<br/>â€¢ LLM token usage & cost<br/>â€¢ False positive rate<br/>â€¢ Human review throughput"]

        Alerts["Alert System<br/>â€¢ Audit timeout >30min<br/>â€¢ Agent failure rate >10%<br/>â€¢ LLM cost spike >$X/day<br/>â€¢ Data quality gate failure<br/>â€¢ Databricks connection loss"]

        Dashboards["Observability Dashboard<br/><sub>Datadog, Grafana, or Databricks UI</sub><br/>â€¢ Real-time audit progress<br/>â€¢ Cost tracking<br/>â€¢ Agent performance<br/>â€¢ SLA compliance"]
    end

    subgraph CostOptimization["ğŸ’° COST OPTIMIZATION STRATEGIES"]
        Strategy1["<b>Strategy 1: Tool-First Approach</b><br/>SQL/Python tools filter to suspicious subset<br/>â†’ Only invoke LLM on <10% of transactions<br/>Example: 10,000 transactions â†’ 800 LLM calls"]

        Strategy2["<b>Strategy 2: Model Tiering</b><br/>Simple cases: GPT-4o-mini ($0.15/1M tokens)<br/>Complex cases: Claude Sonnet ($3/1M tokens)<br/>Ambiguous: GPT-4 or Claude Opus (rare)"]

        Strategy3["<b>Strategy 3: Batch Processing</b><br/>Group 50-100 transactions per LLM call<br/>â†’ Reduces API overhead 50x<br/>Use context window efficiently"]

        Strategy4["<b>Strategy 4: Caching</b><br/>Cache vendor profiles, approval patterns<br/>Avoid re-computing same analysis<br/>Redis TTL: 24 hours"]
    end

    %% Main Flow Connections
    TimeTrigger -->|Hourly| Orchestrator
    EventTrigger -->|On data arrival| Orchestrator
    ManualTrigger -->|API call| Orchestrator

    Gold -->|Query| Orchestrator
    KG -->|Entity lookup| Orchestrator

    Orchestrator <-->|State management| StateStore

    Orchestrator ==>|Parallel dispatch| Agent1
    Orchestrator ==>|Parallel dispatch| Agent2
    Orchestrator ==>|Parallel dispatch| Agent3

    Agent1 -->|Results| Orchestrator
    Agent2 -->|Results| Orchestrator
    Agent3 -->|Results| Orchestrator

    Orchestrator ==>|Sequential| Agent4
    Agent4 -->|Enriched context| Orchestrator

    Orchestrator ==>|Sequential| Agent5
    Agent5 -->|Classifications| Aggregator

    Aggregator --> Classifier
    Classifier --> Explainer

    Explainer ==>|Write flags| FlagDB

    Orchestrator ==>|Continuous logging| Agent6
    Agent6 ==>|Write logs| AuditDB

    FlagDB ==>|Display| Frontend
    Frontend ==>|User actions| HumanFeedback

    HumanFeedback -->|Batch weekly| FeedbackAnalyzer
    FeedbackAnalyzer -->|Auto-update| RuleTuner
    FeedbackAnalyzer -->|Retrain| ModelRetrainer

    RuleTuner -.->|Update configs| Agent1
    RuleTuner -.->|Update configs| Agent2
    RuleTuner -.->|Update configs| Agent3
    ModelRetrainer -.->|Deploy new models| Agent3

    AuditDB -->|Aggregate| Metrics
    Metrics -->|Threshold checks| Alerts
    Metrics -->|Visualize| Dashboards

    %% Styling
    classDef dataStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef agentStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    classDef outputStyle fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    classDef feedbackStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef monitorStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px

    class Bronze,Silver,Gold,KG dataStyle
    class Orchestrator,Agent1,Agent2,Agent3,Agent4,Agent5,Agent6 agentStyle
    class FlagDB,AuditDB,Frontend outputStyle
    class HumanFeedback,FeedbackAnalyzer,RuleTuner,ModelRetrainer feedbackStyle
    class Metrics,Alerts,Dashboards monitorStyle
